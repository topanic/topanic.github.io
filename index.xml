<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>topanic&#39;s 🫡</title>
        <link>https://topanic.site/</link>
        <description>Recent content on topanic&#39;s 🫡</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <copyright>Github:topanic. All rights reserved.</copyright>
        <lastBuildDate>Sat, 27 Jan 2024 23:58:50 +0800</lastBuildDate><atom:link href="https://topanic.site/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Jetson Nano tips</title>
        <link>https://topanic.site/p/jetson-nano-tips/</link>
        <pubDate>Sat, 27 Jan 2024 23:58:50 +0800</pubDate>
        
        <guid>https://topanic.site/p/jetson-nano-tips/</guid>
        <description>&lt;h1 id=&#34;jetson-nano&#34;&gt;jetson nano&lt;/h1&gt;
&lt;p&gt;Jetpack: 4.6.1&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cuda: 10.2.300&lt;/li&gt;
&lt;li&gt;cuDNN: 8.2.1.32&lt;/li&gt;
&lt;li&gt;TensorRT: 8.2.1.8&lt;/li&gt;
&lt;li&gt;OpenCV: 4.1.1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Python: 3.6.9&lt;/p&gt;
&lt;h1 id=&#34;python版本和yolov5&#34;&gt;python版本和yolov5&lt;/h1&gt;
&lt;h2 id=&#34;jetson-nano-自带python36与yolov5冲突&#34;&gt;jetson nano 自带python3.6与yolov5冲突&lt;/h2&gt;
&lt;p&gt;yolov5 需要满足python版本&lt;strong&gt;大于3.7&lt;/strong&gt;，而jetson nano的官方镜像自带版本为 &lt;code&gt;python3.6.9&lt;/code&gt;，自带的tensorrt也仅仅包含在3.6中，且网上大部分教程都是围绕3.6展开。所以python和yolov5之间在nano中有些冲突。&lt;/p&gt;
&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;
&lt;p&gt;以下是我可以想到的两种解决方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;继续使用 jetson nano 中自带的 python3.6.9。此类方法比较常见，网上大部分教程也是采用次方法。主要思想是在clone yolov5代码时选择早期版本，可以适配python3.6的。&lt;em&gt;这种解决办法网上教程参差不齐还是需要多辨认一下。&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更换更高版本的python。在这里我使用的是这种方法，理论上来讲可以最高可以换到python3.9，我这里只是为了能跑通yolov5就选择了 &lt;code&gt;python3.7.12&lt;/code&gt; 。下面部分内容主要讲解此配置方案需要注意的点。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;包管理工具&#34;&gt;包管理工具&lt;/h3&gt;
&lt;p&gt;环境管理工具方面选择miniforge3，因为nano架构为aarch64，不同于我们PC的amd64，所以没办法使用anaconda。具体安装方法google搜一下就好，这个简单。&lt;/p&gt;
&lt;h3 id=&#34;deepstream的适配性&#34;&gt;deepstream的适配性&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;如果不知道deepstream是什么东西，那就说明还没有这个需求，可以直接跳过这块，需要的时候再看。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;如果要用到deepstream，其版本要求严格对应cuda版本、jetpack版本等，需要在nvidia官网看好，它也和python版本有严格的对应关系。我在这里使用的是&lt;code&gt;Deepstream-6.0&lt;/code&gt;，理论与它适配的python版本是3.6.9，我使用python3.7也可以正常运行。&lt;/p&gt;
&lt;p&gt;deepstream的安装教程网络上良莠不齐，注意分辨。
这里给出一个比较好的&lt;a class=&#34;link&#34; href=&#34;https://github.com/ultralytics/yolov5/issues/9627&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;教程&lt;/a&gt;，里面既有对yolov5的安装，也有对deepstream的安装。但还是有刚刚那个python版本问题，其使用的python3.69，所以还是以上&lt;strong&gt;解决方法&lt;/strong&gt;中的两个二选一。剩下部分就按照教程走就好。&lt;/p&gt;
&lt;h2 id=&#34;第二种解决办法的后续流程&#34;&gt;第二种解决办法的后续流程&lt;/h2&gt;
&lt;h3 id=&#34;tensorrt&#34;&gt;tensorrt&lt;/h3&gt;
&lt;p&gt;tensorrt是一个需要着重说明的点。jetson nano的系统环境其实封装的很好了，其&lt;strong&gt;系统环境中的python3.6.9自带有tensorrt&lt;/strong&gt;。可以直接通过 &lt;code&gt;import tensorrt&lt;/code&gt; 来使用。&lt;/p&gt;
&lt;p&gt;但如果要使用高版本的python，就没有tensorrt了，需要自己去编译。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为什么不能通过pip安装？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;还是上面提到的，jetson nano是aarch64架构，pypi官网上无论是tensorrt包还是nvidia-tensorrt包，它的下载栏里面很明显可以看到都是x86架构的，没有办法直接pip下载。&lt;/p&gt;
&lt;p&gt;如果留心就会发现tensorrt的python包存在路径：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;/usr/lib/python3.6/dist-packages/tensorrt&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;包含以下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;__ init __.py&lt;/li&gt;
&lt;li&gt;tensorrt.so&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;内容极少，后者就是关键部分，一个编译后的程序函数库文件，我们现在需要做的就围绕它进行。&lt;/p&gt;
&lt;h4 id=&#34;低版本python直接链接&#34;&gt;低版本python：直接链接&lt;/h4&gt;
&lt;p&gt;如果你创建了python3.6的虚拟环境，发现tensorrt在你的虚拟环境下用不了，就可以简单一点，直接用&lt;code&gt;ln -s&lt;/code&gt;把这个tensorrt包链接到你的&lt;strong&gt;虚拟环境的site-packages&lt;/strong&gt;中。&lt;/p&gt;
&lt;h4 id=&#34;高版本pythontensorrt-python-bindings&#34;&gt;高版本python：TensorRT Python Bindings&lt;/h4&gt;
&lt;p&gt;如果是高版本python，例如我这里使用的python3.7.12版本就不能直接链接。这里就要使用到&lt;strong&gt;TensorRT Python Bindings&lt;/strong&gt;工具，来编译生成对应版本的&lt;strong&gt;tensorrt.so&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;这里给出两个步骤教程，这两个教程对比着看，就大致学会安装方法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://forums.developer.nvidia.com/t/tensorrt-on-jetson-with-python-3-9/196131&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Tensorrt on Jetson with python 3.9&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/NVIDIA/TensorRT/tree/release/8.2/python&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;官方教程&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;注意点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;看好版本，你要使用的python版本，下载好对应的python版本源码。&lt;/li&gt;
&lt;li&gt;TensorRT工具的版本，与我们对应的是&lt;strong&gt;release/8.2&lt;/strong&gt;分支。&lt;/li&gt;
&lt;li&gt;cmake版本要高于3.13，系统自带的不满足。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;操作过程简述&#34;&gt;操作过程简述&lt;/h4&gt;
&lt;p&gt;研究好了上面给的两个教程之后，理论上讲你的目录中需要并列存在以下三个目录：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;TensorRT：github上克隆的官方工具包&lt;/li&gt;
&lt;li&gt;pybind11：编译过程中需要使用的子模块&lt;/li&gt;
&lt;li&gt;python3.x.x：准备好的python include源码，需要加入&lt;strong&gt;pyconfig.h&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第二个我感觉不需要，因为clone了TensorRT之后，使用&lt;code&gt;git submodule update --init --recursive&lt;/code&gt;就会把pybind11一同clone下来。不过放着也无所谓。&lt;/p&gt;
&lt;p&gt;有一个&lt;strong&gt;教程中没有提到的很重要的一个环节&lt;/strong&gt;需要做。需要进入：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;TensorRT/parsers/onnx/third_party/onnx/third_party/pybind11&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;目录下（如果没有该目录就是没有更新子模块），输入&lt;code&gt;git checkout -b v2.6&lt;/code&gt;，降低pybind11版本，最新版本有bug。&lt;/p&gt;
&lt;p&gt;完成后把参数调整成你需要的之后，执行&lt;strong&gt;build.sh&lt;/strong&gt;大概率就是对的，正常情况下会长时间卡在：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[ 16%] Building CXX object CMakeFiles/tensorrt.dir/src/infer/pyGraph.cpp.o
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[ 16%] Building CXX object CMakeFiles/tensorrt.dir/src/infer/pyPlugin.cpp.o
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[ 25%] Building CXX object CMakeFiles/tensorrt.dir/src/infer/pyAlgorithmSelector.cpp.o
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[ 33%] Building CXX object CMakeFiles/tensorrt.dir/src/infer/pyInt8.cpp.o
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[ 41%] Building CXX object CMakeFiles/tensorrt.dir/src/infer/pyFoundationalTypes.cpp.o
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[ 50%] Building CXX object CMakeFiles/tensorrt.dir/src/infer/pyCore.cpp.o
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[ 58%] Building CXX object CMakeFiles/tensorrt.dir/src/parsers/pyCaffe.cpp.o
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[ 66%] Building CXX object CMakeFiles/tensorrt.dir/src/parsers/pyUff.cpp.o
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[ 75%] Building CXX object CMakeFiles/tensorrt.dir/src/utils.cpp.o
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[ 91%] Building CXX object CMakeFiles/tensorrt.dir/src/parsers/pyOnnx.cpp.o
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[ 91%] Building CXX object CMakeFiles/tensorrt.dir/src/pyTensorRT.cpp.o
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;因为这个需要编译一会，如果很快就结束了，大概率是寄了，重新再检查错误吧。&lt;/p&gt;
&lt;h4 id=&#34;操作过程中的问题合集&#34;&gt;操作过程中的问题合集&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;报错： c++: internal compiler error: Killed (program cc1plus)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;编译过程中内存爆了，看&lt;a class=&#34;link&#34; href=&#34;https://aijishu.com/a/1060000000221025&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;这篇文档&lt;/a&gt;的nano设置部分。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;报错： &amp;hellip; SetuptoolsDeprecationWarning: setup.py install is deprecated. &amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;python的setuptools版本太高，降版本：&lt;code&gt;pip install setuptools==58.2.0&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;报错： &amp;ldquo;No module named &amp;rsquo;tensorrt.tensorrt&amp;rsquo;&amp;rdquo; for generated wheel file&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;遇到这种情况时候，整个流程好像没什么错，但是会发现安装完成之后，tensorrt包里面没有最重要的&lt;strong&gt;tensorrt.so&lt;/strong&gt;文件。遇到这种情况就降&lt;strong&gt;pybind11&lt;/strong&gt;版本就好。
&lt;a class=&#34;link&#34; href=&#34;https://github.com/NVIDIA/TensorRT/issues/2288&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;issue链接&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;完成&#34;&gt;完成&lt;/h3&gt;
&lt;p&gt;完成上述操作后，带有tensorrt的 python3.7就整好了，可以正常用了，另外还需要装一些 pycuda 就很好装了，去pypi官网查看对应python的版本就好，别装错了&lt;/p&gt;
&lt;h1 id=&#34;带有gstream的opencv&#34;&gt;带有gstream的opencv&lt;/h1&gt;
&lt;p&gt;原nano板上预装了OpenCV，若直接使用&lt;code&gt;nvgstcapture&lt;/code&gt;指令可以打开摄像头代表摄像头连接没问题。&lt;/p&gt;
&lt;p&gt;现在我们由于更换了python版本，若直接通过pip安装就没办法使用gstream，就会导致打不开CSI摄像头，所以我们需要重新编译适用于python3.7.12的opencv。&lt;/p&gt;
&lt;h2 id=&#34;opencv编译过程&#34;&gt;opencv编译过程&lt;/h2&gt;
&lt;p&gt;具体安装过程可以参照此&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/read/cv17612080/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;博客&lt;/a&gt;来完成。&lt;/p&gt;
&lt;p&gt;opencv版本我这里选择了4.5.5，此版本目前适用于我们当前环境。&lt;/p&gt;
&lt;p&gt;cmake那步具体指令可以根据我下面给出的来适当修改：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D OPENCV_GENERATE_PKGCONFIG=ON -D BUILD_EXAMPLES=OFF -D INSTALL_PYTHON_EXAMPLES=OFF -D INSTALL_C_EXAMPLES=OFF -D PYTHON_EXECUTABLE=$(which python2) -D BUILD_opencv_python2=OFF -D PYTHON3_EXECUTABLE=/home/bad/miniforge3/envs/yolov5/bin/python3.7m -D WITH_GSTREAMER=ON -D PYTHON3_INCLUDE_DIR=/home/bad/miniforge3/envs/yolov5/include/python3.7m -D PYTHON3_PACKAGES_PATH= /home/bad/miniforge3/envs/yolov5/lib/python3.7/site-packages -D PYTHON3_LIBRARY=/home/bad/miniforge3/envs/yolov5/lib/libpython3.7m.so -D PYTHON3_NUMPY_INCLUDE_DIRS=/home/bad/miniforge3/envs/yolov5/lib/python3.7/site-packages/numpy/core/include -D PYTHON_DEFAULT_EXECUTABLE=/home/bad/miniforge3/envs/yolov5/bin/python3.7m ..
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;最好根据上面给出的cmake指令来进行cmake，不然会make失败&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;建议在make的时候使用 -j4， 这样会快一些，当make到92%的时候使用 -j1，避免卡死&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;编译完成后会在根目录生成一个cv目录，此时只需要把cv目录的二进制文件移动到conda中的python3.7环境中即可。完成以上就可以在当前的python环境中使用带gstream的opencv。&lt;/p&gt;
&lt;h1 id=&#34;pt---onnx---trt&#34;&gt;.pt -&amp;gt; .onnx -&amp;gt; .trt&lt;/h1&gt;
&lt;p&gt;在nano板上使用直接使用pytorch来进行推理的话处理速度会很慢，会导致视频帧率变低。所以在nano板等嵌入式环境中部署深度学习时最好使用tensorrt推理的形式进行，这也是上文讲解tensorrt编译的目的，可以加快一点处理速度。&lt;/p&gt;
&lt;p&gt;使用tensorrt推理需要把原pt文件转换为推理引擎文件，通常以 &lt;em&gt;.engine&lt;/em&gt;或者 &lt;em&gt;.trt&lt;/em&gt;为主，这两者貌似是一个东西，区别不大，具体有什么区别还需要再研究研究。&lt;/p&gt;
&lt;p&gt;从权重文件转换为引擎文件的方式有多种，这里列举主要的三个转换入口：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TF-TRT，要求是 TensorFlow 模型&lt;/li&gt;
&lt;li&gt;ONNX 模型格式&lt;/li&gt;
&lt;li&gt;使用 TensorRT API 手动把模型搭起来，然后把参数加载进去&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;第三种需要使用tensorrt api手动编写网络，比较麻烦，开源项目&lt;a class=&#34;link&#34; href=&#34;https://github.com/wang-xinyu/tensorrtx&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Tensorrtx&lt;/a&gt;就使用这种方法来获得.pt文件，但如果网络结构出现问题，那就需要修改此网络结构，极其麻烦。有需要就用一下上述开源项目中的一些模型就好，在以上模型中进行修改。&lt;/p&gt;
&lt;p&gt;在本文中使用第二种方法来获得引擎文件，以下是具体流程。&lt;/p&gt;
&lt;h2 id=&#34;pt---onnx&#34;&gt;.pt -&amp;gt; .onnx&lt;/h2&gt;
&lt;p&gt;这步的转化晚上教程很多，可以参考以下我找的，&lt;a class=&#34;link&#34; href=&#34;https://github.com/tsieyy/UNet-dataset&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;U-Net仓库&lt;/a&gt;，Main文件夹中的**_04pt2onnx.py**，此代码亲测可用。&lt;/p&gt;
&lt;h2 id=&#34;onnx---trt&#34;&gt;.onnx -&amp;gt; .trt&lt;/h2&gt;
&lt;p&gt;该步骤麻烦一点，需要源码编译&lt;strong&gt;onnx-tensorrt&lt;/strong&gt;，具体步骤可以查看该&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/ll0629/article/details/125082759?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168205015716800226573759%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;amp;request_id=168205015716800226573759&amp;amp;biz_id=0&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-125082759-null-null.142%5ev86%5einsert_down28,239%5ev2%5einsert_chatgpt&amp;amp;utm_term=unet%20tensorrt&amp;amp;spm=1018.2226.3001.4187&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;博客&lt;/a&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;报错： 缺少 &amp;lt;TensorrtRuntimeAPI.h&amp;gt; 文件（我不太确定是不是叫这个名字了，反正是一个差不多的名字）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;若出现上述错误，需要在项目文件的CmakeLists.txt文件中添加这个头文件（具体流程百度搜一下，貌似是叫一个 &lt;em&gt;include_directories&lt;/em&gt; 的指令，记不清了），该头文件的具体位置可以使用：&lt;code&gt;sudo find / -name TensorrtRuntimeAPI(按实际情况做修改).h&lt;/code&gt; 这条指令来对根目录进行查找，一般情况下就只能找到一个。然后把包含这个头文件的include文件夹放在cmake里边，删掉build文件夹里面的东西重新cmake。cmake没有类似于clean的指令，所以务必要删掉重新来。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：如果cmake里面有需要对python目录进行修改的就改成我们的conda环境。此步骤记不太清了主要是。&lt;/p&gt;
&lt;p&gt;安装完成之后就可以使用下面的指令来进行转换了，如果有报错大概率.onnx文件就有问题：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;onnx2trt best_unet.onnx -o best_unet.trt&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;以上步骤做完之后修改编写业务逻辑的代码就可以使用.trt文件来进行推理了。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Archives</title>
        <link>https://topanic.site/archives/</link>
        <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
        
        <guid>https://topanic.site/archives/</guid>
        <description></description>
        </item>
        <item>
        <title>About</title>
        <link>https://topanic.site/about/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://topanic.site/about/</guid>
        <description>&lt;h1 id=&#34;null-void-nil-none-and-nothing&#34;&gt;Null, Void, Nil, None and Nothing&amp;hellip;&lt;/h1&gt;
</description>
        </item>
        <item>
        <title>Links</title>
        <link>https://topanic.site/links/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://topanic.site/links/</guid>
        <description>&lt;p&gt;If you want to join the friend link, you can contact me through the email on the left. kiss kiss~&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Search</title>
        <link>https://topanic.site/search/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://topanic.site/search/</guid>
        <description></description>
        </item>
        
    </channel>
</rss>
